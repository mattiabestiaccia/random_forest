{
  "experiment_name": "advanced_stats_assatigue_k2_WithModel",
  "config": {
    "dataset_path": "/home/brusc/Projects/random_forest/datasets/dataset_rgb_salt_and_pepper_25/original",
    "area_name": "assatigue",
    "feature_method": "advanced_stats",
    "k_features": 2,
    "output_dir": "/home/brusc/Projects/random_forest/experiments_organized_2/salt_and_pepper_output/dataset_rgb_salt_and_pepper_25/assatigue/original/k2/advanced_stats",
    "n_estimators": 50,
    "test_size": 0.2,
    "random_state": 42,
    "cv_folds": 5
  },
  "dataset_info": {
    "data_directory": "/home/brusc/Projects/random_forest/datasets/dataset_rgb_salt_and_pepper_25/original",
    "area_name": "assatigue",
    "total_images": 116,
    "classes": {
      "low_veg": 40,
      "water": 40,
      "trees": 36
    },
    "image_shape": [
      3,
      128,
      128
    ],
    "total_features_available": 54,
    "feature_method": "advanced_stats",
    "dataset_type": "original",
    "k_features": 2
  },
  "feature_selection": {
    "method": "SelectKBest_k2",
    "num_features": 2,
    "selected_features": [
      "B_cv",
      "B_p50"
    ],
    "feature_scores": [
      0.7538827810961133,
      0.7158284982142438
    ]
  },
  "performance": {
    "test_accuracy": 0.7083333333333334,
    "cv_mean_accuracy": 0.8021739130434783,
    "cv_std_accuracy": 0.0837450447141662,
    "cv_scores": [
      0.75,
      0.9565217391304348,
      0.7391304347826086,
      0.8260869565217391,
      0.7391304347826086
    ],
    "classification_report": {
      "low_veg": {
        "precision": 0.5714285714285714,
        "recall": 0.5,
        "f1-score": 0.5333333333333333,
        "support": 8.0
      },
      "trees": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 8.0
      },
      "water": {
        "precision": 0.5555555555555556,
        "recall": 0.625,
        "f1-score": 0.5882352941176471,
        "support": 8.0
      },
      "accuracy": 0.7083333333333334,
      "macro avg": {
        "precision": 0.708994708994709,
        "recall": 0.7083333333333334,
        "f1-score": 0.7071895424836602,
        "support": 24.0
      },
      "weighted avg": {
        "precision": 0.708994708994709,
        "recall": 0.7083333333333334,
        "f1-score": 0.7071895424836602,
        "support": 24.0
      }
    },
    "confusion_matrix": [
      [
        4,
        0,
        4
      ],
      [
        0,
        8,
        0
      ],
      [
        3,
        0,
        5
      ]
    ]
  },
  "model_files": {
    "trained_model": "trained_model.joblib",
    "scaler": "scaler.joblib",
    "feature_selector": "feature_selector.joblib",
    "feature_names": "feature_names.json"
  },
  "timestamp": "2025-07-22T16:05:29.591700"
}