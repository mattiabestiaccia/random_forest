{
  "experiment_name": "hybrid_assatigue_k5_WithModel",
  "config": {
    "dataset_path": "/home/brusc/Projects/random_forest/datasets/dataset_rgb_salt_and_pepper_25/original",
    "area_name": "assatigue",
    "feature_method": "hybrid",
    "k_features": 5,
    "output_dir": "/home/brusc/Projects/random_forest/experiments_organized_2/salt_and_pepper_output/dataset_rgb_salt_and_pepper_25/assatigue/original/k5/hybrid",
    "n_estimators": 50,
    "test_size": 0.2,
    "random_state": 42,
    "cv_folds": 5
  },
  "dataset_info": {
    "data_directory": "/home/brusc/Projects/random_forest/datasets/dataset_rgb_salt_and_pepper_25/original",
    "area_name": "assatigue",
    "total_images": 116,
    "classes": {
      "low_veg": 40,
      "water": 40,
      "trees": 36
    },
    "image_shape": [
      3,
      128,
      128
    ],
    "total_features_available": 540,
    "feature_method": "hybrid",
    "dataset_type": "original",
    "k_features": 5
  },
  "feature_selection": {
    "method": "SelectKBest_k5",
    "num_features": 5,
    "selected_features": [
      "R_skew",
      "R_p75",
      "B_cv",
      "B_p50",
      "R_wst_std_0"
    ],
    "feature_scores": [
      0.6788243146583359,
      0.6780313241924751,
      0.7538827810961133,
      0.7240814401956344,
      0.7607031651967155
    ]
  },
  "performance": {
    "test_accuracy": 0.9583333333333334,
    "cv_mean_accuracy": 0.9739130434782609,
    "cv_std_accuracy": 0.052173913043478265,
    "cv_scores": [
      1.0,
      1.0,
      0.8695652173913043,
      1.0,
      1.0
    ],
    "classification_report": {
      "low_veg": {
        "precision": 0.8888888888888888,
        "recall": 1.0,
        "f1-score": 0.9411764705882353,
        "support": 8.0
      },
      "trees": {
        "precision": 1.0,
        "recall": 1.0,
        "f1-score": 1.0,
        "support": 8.0
      },
      "water": {
        "precision": 1.0,
        "recall": 0.875,
        "f1-score": 0.9333333333333333,
        "support": 8.0
      },
      "accuracy": 0.9583333333333334,
      "macro avg": {
        "precision": 0.9629629629629629,
        "recall": 0.9583333333333334,
        "f1-score": 0.9581699346405229,
        "support": 24.0
      },
      "weighted avg": {
        "precision": 0.9629629629629629,
        "recall": 0.9583333333333334,
        "f1-score": 0.9581699346405229,
        "support": 24.0
      }
    },
    "confusion_matrix": [
      [
        8,
        0,
        0
      ],
      [
        0,
        8,
        0
      ],
      [
        1,
        0,
        7
      ]
    ]
  },
  "model_files": {
    "trained_model": "trained_model.joblib",
    "scaler": "scaler.joblib",
    "feature_selector": "feature_selector.joblib",
    "feature_names": "feature_names.json"
  },
  "timestamp": "2025-07-22T16:10:46.262261"
}