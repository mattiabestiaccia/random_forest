# Multiscale Feature Extraction with Wavelet Scattering for UAV Vegetation Classification via Random Forests

## Abstract
In recent years, techniques for analyzing cultivated fields and natural landscapes have increasingly adopted remote sensing technologies, such as UAV drones, satellite imagery, and other tools capable of capturing high- or low-resolution images. Among the methodologies most commonly used are the Normalized Difference Vegetation Index (NDVI) and the Leaf Area Index (LAI), which allow the monitoring and assessment of vegetation cover and plant health. However, these techniques exhibit well-known limitations, including sensitivity to atmospheric conditions, the requirement for frequent calibration, and the complexity of data interpretation. The ability to obtain timely and localized information is critical both in the context of precision agriculture - where biomass estimation and crop yield forecasting depend on accurate interpretation of vegetation cover data - and in the monitoring of natural environments such as salt marshes and tidal zones, where distinguishing between vegetated areas, open water bodies, and artificial surfaces is essential. Access to spatially explicit data allows not only the mapping of vegetation distribution, but also the detection of anthropogenic elements, thereby enhancing the effectiveness of management and conservation strategies.

In this study, we propose an innovative framework that combines a Random Forest classifier with a white-box feature extractor based on the Wavelet Scattering Transform (WST) to optimize the collection and analysis of remote sensing data acquired by drones over agricultural fields and wetland ecosystems. The use of WST provides interpretable, mathematically grounded features that retain spatial and spectral characteristics across multiple scales, enhancing model transparency and enabling better understanding of the decision process. As a preprocessing step, image denoising was performed using a Convolutional Neural Network enhanced with wavelet transform capabilities, trained to suppress real-world noise and improve robustness to variations in illumination, texture, and spatial resolution.

The study was conducted across three locations in the Chesapeake Bay region (Maryland, USA): Poplar Island, Assateague Island, and Sunset Island. Poplar Island is an ecological restoration site where dredged materials from Chesapeake Bay navigation channels are used to reconstruct tidal marsh habitats. Assateague Island, a barrier island, serves as a relatively natural reference environment, while Sunset Island represents a highly developed coastal setting. These sites are characterized by diverse ecological conditions, including dynamic patterns of sediment deposition and erosion, tidal and ecological forces, and marked seasonal variability in vegetation. These dynamics significantly influence ecosystem balance and pose considerable challenges for long-term monitoring and management of marsh platforms.


## Keywords
Features Classification, Wavelet denoising, Wavelet Scattering Transform, Vegetation boundaries detection, Ecological Restoration, Wetland NBS, Drones, UAVs Imagery

## INTRODUCTION
Coastal wetlands—such as salt marshes, mangroves, and estuaries—are among the most valuable and biodiverse ecosystems on Earth. They provide essential ecological functions and ecosystem services directly tied to human well-being, including carbon sequestration and storage (blue carbon), filtration of pollutants and excess nutrients, and natural protection against storm surges and coastal erosion. These ecosystems support a wide range of plant and animal species, many of which are endemic or threatened, and contribute significantly to fisheries and tourism, providing vital economic resources for millions of people worldwide [13,14,15]. Despite their importance, coastal wetlands are increasingly endangered by a combination of anthropogenic and natural stressors. Coastal urbanization, land conversion for agriculture and industry, and pollution have led to habitat fragmentation and biodiversity loss. These pressures are further intensified by climate change—rising sea levels cause permanent inundation, increasing temperatures alter species composition, and ocean acidification degrades overall habitat health. Eutrophication, driven by nutrient runoff from agriculture and industry, exacerbates these threats by fueling harmful algal blooms, reducing oxygen levels, and endangering aquatic life [16]. 

Poplar Island, located in the Chesapeake Bay, exemplifies the challenges faced by coastal environments. It has experienced significant land loss due to erosion and subsidence, further exacerbated by sea level rise. In response, a restoration project was launched using dredged sediment to rebuild tidal marsh habitats. Despite these efforts, the balance between platform accretion and erosion remains precarious. Marsh platform morphology is shaped by complex factors, including vegetation distribution, tidal dynamics, and the structure of tidal creek networks. Restoration design—guided by research on tidal morphology and dynamics—aims to enhance the ecosystem’s resilience to environmental change, but its success depends on continuous monitoring and adaptive management. Salt marshes like those on Poplar Island are especially vulnerable to erosion and sedimentation dynamics shaped by both natural forces and human influence. Extreme weather events—such as hurricanes and storm surges—and the ongoing rise in sea level pose serious risks to the integrity of these environments. During such events, wave and current activity can accelerate shoreline erosion, particularly in unvegetated areas where soil stability is reduced. Vegetation plays a crucial role in mitigating erosion by slowing water flow and promoting sediment accumulation. However, the capacity of salt marshes to maintain equilibrium is increasingly undermined by disrupted sediment fluxes and the cumulative impacts of climate change and human activities. Salt marshes also act as important sinks for microplastics, trapping these particles in sediments. Recent studies have shown that microplastic accumulation in marsh environments increases with surrounding urbanization, suggesting that marsh sediments can reflect the anthropogenic impact on coastal ecosystems [9].

Given the aforementioned growing threats, monitoring and protecting the sustainability of coastal wetland ecosystems has become an urgent priority. Integrated coastal zone management, ecological restoration of degraded areas, and evidence-based conservation strategies are essential to preserving these fragile ecosystems. Advanced technologies such as remote sensing, spatial data analysis, and ecological modeling provide new opportunities to improve our understanding of wetland dynamics and develop more effective conservation strategies. Several studies in the literature have addressed salt marsh monitoring and conservation using approaches similar to those proposed in this work. For instance, long-term analyses of marsh platform evolution have highlighted habitat losses linked to sea level rise and coastal erosion [8]. These studies often rely on empirical data and predictive models to estimate habitat loss and forecast the potential disappearance of entire marsh ecosystems within this century, emphasizing the urgent need to understand and mitigate the drivers of decline. In recent years, the monitoring of croplands and natural landscapes has greatly benefited from the widespread adoption of remote sensing technologies, including UAVs, satellite imagery, and other high- and low-resolution imaging tools [1,2]. These technologies offer effective alternatives to traditional methods—such as the Normalized Difference Vegetation Index (NDVI) and field surveys—which, although long considered the standard for assessing biomass and other environmental parameters, are time-consuming, labor-intensive, and often impractical at large scales or in hard-to-access areas [3,4,5]. Remote sensing has proven particularly valuable for monitoring complex ecosystems like coastal wetlands, overcoming the challenges of site accessibility, hydrologic fluctuations, and topographic variability. Thanks to its ability to collect reflectance data over large areas efficiently and cost-effectively, remote sensing has become a key tool for wetland monitoring [17,18,19]. UAV technology, in particular, has rapidly evolved, offering ultra-high spatial resolution, multisensor integration, high portability, and low cost. UAVs bridge the gap between field surveys and traditional satellite or aerial platforms, enabling local and regional-scale vegetation monitoring. Today, UAVs are widely used for mapping wetland vegetation [20,21], monitoring invasive species, estimating biomass, and supporting ecological restoration, making them indispensable tools for wetland management and conservation [22,23,24,25]. Before applying classification and segmentation techniques, an essential step in UAV-based image analysis is the reduction of noise introduced by sensor imperfections, lighting variability, and environmental conditions. Image denoising plays a critical role in improving data quality, as noise can obscure fine spatial details crucial for reliable classification. Among the various denoising approaches, wavelet-based methods have shown remarkable effectiveness thanks to their ability to represent image features across multiple scales and directions. The wavelet transform is particularly well-suited for distinguishing between high-frequency noise and meaningful texture information, preserving edges and structural features during the denoising process [28,29]. Recent studies have explored the integration of wavelet transforms with deep learning models, including convolutional neural networks (CNNs), to further enhance denoising performance while maintaining computational efficiency. This approach enables improved generalization across heterogeneous datasets and supports downstream tasks such as object detection, vegetation mapping, and land cover classification.

Our research builds upon this context by proposing a machine learning-based approach that employs a Random Forest classifier applied to features extracted through the Wavelet Scattering Transform (WST). The aim of our study is to assess the effectiveness of WST as a feature extractor for the classification task. As a preliminary step, the system performs denoising on UAV-acquired images, often affected by typical issues such as sensor noise, variable illumination, and inconsistent contrast. For this task, we implement the approach proposed by Tian et al. [26] which utilizes a multi-stage wavelet-based convolutional neural network (MWDCNN). This architecture integrates dynamic convolutional blocks (DCB), cascaded wavelet enhancement blocks (WEBs), and residual blocks (RB) to balance denoising performance and computational cost. The wavelet transform allows effective noise suppression while preserving image structure and details, and residual dense architectures refine features to reconstruct clean outputs. Following the denoising stage, the system proceeds with a dedicated feature extraction phase using the Wavelet Scattering Transform (WST), which generates a rich and stable representation of the input data. Subsequently, these extracted features serve as input to a Random Forest classifier, which performs the final classification. The Random Forest algorithm, known for its robustness and ability to handle high-dimensional feature spaces, is leveraged to discriminate between different vegetation types or naturalistic elements based on the rich and stable feature representation provided by the WST.

Section 1 provides an introduction to the key themes addressed in this study. Section 2 presents a detailed description of the methodologies employed. Section 3 discusses the comparative analysis of the proposed approaches, while Section 4 outlines potential directions for future developments.

## MATHERIALS AND METHODS
### Study Site
This study was conducted across three coastal sites in Maryland, USA: Poplar Island, Assateague Island, and Sunset Island. These sites represent a range of coastal environments undergoing varying degrees of ecological restoration, erosion, and habitat dynamics.

#### Poplar Island
The Paul S. Sarbanes Ecosystem Restoration Project on Poplar Island is a large-scale ecological restoration initiative utilizing dredged sediments from the navigation channels leading to the Port of Baltimore. Poplar Island, currently measuring approximately 5.6 km in length and 0.8 km in width, exemplifies a coastal island severely impacted by erosion and sea level rise. The restoration project, led by the United States Army Corps of Engineers (USACE) and the Maryland Department of Transportation Maryland Port Administration (MDOT MPA), seeks to restore the island to its historical footprint as recorded in 1847 [32]. Approximately 694 hectares of tidal wetlands, uplands, and embayment habitats are being reconstructed through the placement of 68 million cubic yards of dredged material [33]. The island is organized into diked containment cells to manage sediment placement, with the final configuration consisting of roughly equal portions of tidal marsh and upland habitats.

#### Assateague Island
Assateague Island is a barrier island stretching over 60 km along the coasts of Maryland and Virginia. It is managed primarily by the National Park Service and the U.S. Fish and Wildlife Service and is known for its dynamic landscape shaped by wind, waves, and tides. Unlike Poplar Island, Assateague has not undergone major artificial restoration using dredged material, but instead serves as a relatively natural reference site. The island hosts extensive dune systems, maritime forests, and salt marshes, providing a diverse array of coastal habitats. Its inclusion in this study offers a valuable comparison to more intensively managed restoration sites.

#### Sunset Island
Sunset Island is a small man-made island located in the Isle of Wight Bay, near Ocean City, Maryland. Unlike Poplar and Assateague, Sunset Island represents a highly developed environment, primarily residential with limited natural habitat. While not a restoration site, its inclusion in this study serves to contrast natural and restored coastal ecosystems with urbanized landscapes. Observations from Sunset Island provide insight into the ecological patterns present in human-altered coastal systems.

### Dataset
A dataset was developed using high-resolution imagery acquired during low-altitude UAV surveys conducted over Poplar Island, Assateague Island, and Sunset Island (Maryland, USA) in December 2024. The aerial data acquisition consisted of four distinct flight missions per site, covering approximately 400 m × 400 m of surface area. All flights were carried out using a DJI Phantom 3 Professional (DJI-P3P) drone equipped with two sensors: the integrated DJI FC300X RGB camera and an additional multispectral camera. Flight plans were created using the Pix4D Capture application, with key parameters set to 80% longitudinal overlap, 60% lateral overlap, and a constant flight altitude of 40 meters. These settings ensured complete and consistent spatial coverage, minimizing gaps between adjacent flight lines. The additional multispectral payload reduced the drone’s flight autonomy, which was accounted for during mission planning.
The RGB imagery collected by the FC300X sensor achieved a Ground Sample Distance (GSD) of approximately 1.8 cm, while the multispectral imagery had a GSD of approximately 2.8 cm. These values were computed based on sensor specifications, pixel size, focal length, and flight altitude, guaranteeing a high spatial resolution suitable for fine-scale environmental analysis.
The resulting imagery, encompassing a variety of coastal and wetland environments—including marshlands, small watercourses, and vegetated areas—was used to build a texture-based dataset. Representative samples of key environmental classes were manually extracted from the images, including low vegetation, trees, water, and gardens. The annotation process was implemented through a Python-based workflow that involved extracting and labeling 128×128 pixel patches from the orthomosaics. For each class, 40 image patches were selected per site, resulting in the creation of a "clean" dataset composed of high-quality, manually annotated samples.
To evaluate the robustness of our approach under limited data conditions, additional smaller datasets were generated for each site, consisting of only 5 and 15 images per class, respectively. These subsets allowed for testing model performance in data-scarce scenarios.
Furthermore, to assess the resilience of the Wavelet Scattering Transform (WST) to image degradation, the original clean datasets were corrupted using various types of synthetic noise at different intensity levels. Specifically, the following types of noise were applied:
- Gaussian noise with σ = 30 and σ = 50
- Poisson noise with λ = 40 and λ = 60
- Speckle noise with variance σ² = 0.15, 0.35, and 0.55
- Salt-and-pepper noise with corruption levels of 5%, 15%, and 25%
- Uniform noise with amplitude ranges of ±10, ±25, and ±40

These noisy variants were used to systematically evaluate the robustness of texture-based representations under different conditions of visual degradation and uncertainty.

### Wavelet Scattering Trasform
The Wavelet Scattering Transform (WST) provides a principled framework for constructing translation-invariant and deformation-stable signal representations through a cascade of wavelet convolutions, modulus nonlinearities, and low-pass filtering. Introduced by Bruna and Mallat [31], this hierarchical architecture mimics the layered structure of convolutional neural networks while remaining mathematically interpretable. Each layer of the scattering network captures progressively higher-order interactions between local signal features, enabling the extraction of multiscale information without relying on learned parameters. The WST preserves discriminative power by retaining energy across multiple frequency bands, and ensures local translation invariance via the application of smoothing operators at the final layer. Building upon this foundation, Mallat [11] reinterprets the scattering transform as a recursive interferometric representation, where interference patterns between wavelet paths encode the geometry of the signal. These representations are constructed via a tree of wavelet transforms interleaved with modulus operators, each acting as a contraction mapping. As a result, the full transform is Lipschitz-continuous and contractive with respect to the input norm i.e., small perturbations in the input lead to proportionally small or diminished variations in the output, ensuring stability and robustness of the representation. One of the key theoretical strengths of the recursive interferometric transform lies in its stability to small elastic deformations, formally expressed through bounds involving the maximum displacement amplitude and the Jacobian of the deformation field. This ensures that the representation remains nearly invariant under smooth, invertible warping of the input signal—a crucial property for analyzing data such as natural images, where local geometric distortions are common. 

Theoretical results further show that the recursive scattering transform provides a favorable trade-off between invariance and discriminability. While rigid invariance—such as that obtained via the modulus of the Fourier transform—may result in excessive dimensionality reduction and information loss, the scattering transform preserves a higher-dimensional embedding capable of separating deformable patterns. Overall, the wavelet scattering framework bridges the gap between deep learning feature extraction and mathematically grounded signal processing. It offers a stable, interpretable, and deformation-tolerant alternative to learned features, and has proven particularly useful in settings with limited training data or strong geometric variability—such as remote sensing, biomedical imaging, and texture classification.

This framework has been implemented in Python using the Kymatio library [12], a dedicated open-source package for scattering transforms. Kymatio was developed by a collaborative team of researchers, and allows for efficient computation of scattering transforms on 1D, 2D, and 3D data, making the methodology accessible and reproducible within scientific and machine learning communities.

### Implemented Machine Learnign Models
The following sections provide a detailed description of each module involved in both pipelines.

#### Denoising step: MWDCNN
[da completare in un secondo momento]
To perform image denoising, we adopted the model presented in [30]. This deep convolutional neural network (CNN) is specifically designed to suppress noise while preserving fine image details. The architecture incorporates a multi-wavelet transform within the network, enabling the extraction of both frequency and structural features and thereby enhancing its ability to discriminate between noise and meaningful image content. Furthermore, a Dynamic Convolutional Block (DCB) adaptively adjusts to varying noise characteristics and scene complexities, increasing robustness under diverse real-world noise conditions. Since high-quality ground truth references are often unavailable for real noisy images, the model is trained using datasets composed of naturally degraded images. The training strategy either employs pseudo-ground truths in a supervised setting or relies on self-supervised methods, which promote effective denoising without requiring explicit clean targets. The architecture is thus optimized for practical deployment, delivering high-quality denoising results on real-world color images while maintaining computational efficiency. 
The denoising module is structured around three core components: the Dynamic Convolutional Block (DCB), the Wavelet Enhancement Blocks (WEBs), and the Residual Block (RB). The DCB utilizes dynamic convolutional layers that adapt their parameters based on the noise level and structural characteristics of the input image. This mechanism enables the model to maintain a favorable balance between denoising performance and computational efficiency, improving its robustness across diverse imaging conditions. The WEBs integrate wavelet transforms with deep learning to extract multiscale hierarchical features, which are then refined through stacked convolutional layers. This design enhances the network’s ability to suppress noise while preserving important image structures and textures. The RB further improves feature quality through densely connected residual layers and skip connections, which facilitate efficient information flow and gradient propagation, ultimately supporting high-fidelity image reconstruction. The resulting architecture, known as Multi-stage Wavelet-based Denoising Convolutional Neural Network (MWDCNN), has demonstrated superior performance compared to established methods such as FFDNet, ADNet, and DnCNN. Specifically, MWDCNN achieves higher Peak Signal-to-Noise Ratio (PSNR) values—up to 29.66 dB compared to 29.32–29.41 dB for competing models—as well as improved results in perceptual and high-level quality metrics, including FSIM, SSIM, LPIPS, and Inception Score, under various noise levels and across multiple benchmark datasets. Qualitative assessments further confirm that MWDCNN produces visually clearer images, with fewer artifacts and better-preserved details than other approaches. The combined use of dynamic convolutions, wavelet-based feature extraction, and deep residual architectures contributes to the model’s adaptability and robustness. In summary, MWDCNN represents a state-of-the-art solution for both synthetic (e.g., Gaussian noise) and real-world image denoising tasks, offering high performance and visual fidelity in practical applications.

#### Random Forest
The Random Forest-based classification module constitutes an efficient, interpretable, and scalable alternative to deep learning techniques for the classification of segmented imagery. Unlike deep neural networks, which typically require large datasets and substantial computational resources, Random Forests are particularly well-suited for scenarios involving limited data availability and restricted hardware capabilities. This classifier offers a flexible design that supports three distinct modes of feature extraction: advanced statistics, Wavelet Scattering Transform (WST), and hybrid approaches. The implementation employs a systematic feature selection strategy using SelectKBest with mutual information (mutual_info_classif) as the scoring function. Features are first standardized using StandardScaler to ensure comparable scales across different feature types. The mutual information criterion measures the dependency between each feature and the target labels, providing a robust, non-parametric approach to feature ranking. The system supports multiple feature subset sizes (k = 2, 5, 10, 20), allowing for investigation of the trade-off between feature dimensionality and classification performance.

Advanced Statistics Feature Extraction: This approach computes 54 statistical features by extracting 18 measures per RGB channel. The feature set encompasses: (1) basic statistics (mean, standard deviation, variance, minimum, maximum, range), (2) distributional shape measures (skewness, kurtosis, coefficient of variation), (3) percentile-based statistics (10th, 25th, 50th, 75th, 90th percentiles, and interquartile range), (4) robust statistical measures (mean absolute deviation), and (5) spatial features including gradient magnitude computed via Sobel operators and edge density using Laplacian edge detection with 90th percentile thresholding.

WST Feature Extraction: The Wavelet Scattering Transform implementation utilizes the kymatio library with J=2 scales and L=8 angles for training (L=4 for inference). This generates approximately 81 scattering coefficients per channel, from which mean and standard deviation statistics are computed, yielding ~162 features per channel for a total of ~486 features across RGB channels. The WST approach provides translation and small deformation invariance while capturing multi-scale textural information.

Hybrid Feature Extraction: This approach combines both statistical and transform-domain information by concatenating the 54 advanced statistics features with the 486 WST features, resulting in a comprehensive 540-dimensional feature space that captures both statistical distributions and structural patterns.

The Random Forest implementation employs an adaptive parameterization strategy that automatically adjusts the number of estimators based on dataset size to optimize the computational efficiency-accuracy trade-off. For mini datasets (~15 images), n_estimators is set to 3 to prevent overfitting; small datasets utilize 10 estimators; while original full-size datasets employ 50 estimators to capture complex decision boundaries. Additional fixed hyperparameters include max_features='sqrt' to control overfitting, min_samples_split=5 and min_samples_leaf=2 to ensure meaningful splits and leaf nodes, and random_state=42 for reproducibility. The evaluation strategy employs stratified k-fold cross-validation (k=5) to ensure balanced class representation across folds. The system implements both holdout validation (80/20 train-test split) and cross-validation assessment, providing comprehensive performance metrics including accuracy, precision, recall, F1-score, and confusion matrices. Feature importance analysis is conducted using mutual information scores to identify the most discriminative features for each classification task. Performance evaluations demonstrate that the Random Forest classifier provides a favorable trade-off between predictive accuracy and computational demands. This balance is particularly advantageous in field applications or edge-computing environments, where processing resources may be constrained. Additionally, the interpretability of the model is further augmented by the ability to extract and analyze feature importances through mutual information calculation. This function offers detailed insight into which features—whether statistical measures or scattering coefficients—are most influential in the classification decisions for each target class. Such interpretability is crucial in scientific applications where transparency of the decision-making process is required. In summary, the Random Forest model presented here offers a compelling combination of efficiency, adaptability, and interpretability. It is particularly well-suited for use cases characterized by limited data availability, the need for rapid inference, or the requirement for transparent and explainable models. Its integration with both statistical and WST-based feature extractors further extends its applicability to domains where both distributional and structural information play central roles, resulting in a versatile and robust component within the broader classification pipeline.
